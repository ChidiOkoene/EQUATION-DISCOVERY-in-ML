{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PiDL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def STRidge(U9, Phi, delta, max_iter=1000, lambda_init=None, tol=1e-6, ridge_reg_param=1e-5, dynamic_ridge=True):\n",
    "    \"\"\"\n",
    "    Enhanced Sequential Threshold Ridge Regression (STRidge)\n",
    "    \n",
    "    Args:\n",
    "        U9 (numpy.ndarray): Time derivative vector (target vector).\n",
    "        Phi (numpy.ndarray): Candidate function library matrix.\n",
    "        delta (float): Threshold tolerance for sparsity.\n",
    "        max_iter (int): Maximum number of iterations.\n",
    "        lambda_init (numpy.ndarray, optional): Initial coefficients for λ. Default is zeros.\n",
    "        tol (float): Convergence tolerance for coefficients.\n",
    "        ridge_reg_param (float): Initial ridge regularization parameter.\n",
    "        dynamic_ridge (bool): Whether to decrease ridge_reg_param over iterations.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The final coefficients λ.\n",
    "    \"\"\"\n",
    "    # Initialize coefficients λ\n",
    "    if lambda_init is None:\n",
    "        lambda_ = np.zeros(Phi.shape[1])\n",
    "    else:\n",
    "        lambda_ = lambda_init\n",
    "    \n",
    "    # Iterative updates\n",
    "    for iteration in range(max_iter):\n",
    "        # Store previous coefficients for convergence check\n",
    "        prev_lambda = lambda_.copy()\n",
    "        \n",
    "        # Step 4: Identify small (I) and large (J) coefficients\n",
    "        I = np.where(np.abs(lambda_) < delta)[0]  # Small coefficients\n",
    "        J = np.where(np.abs(lambda_) >= delta)[0]  # Large coefficients\n",
    "        \n",
    "        # Step 5: Enforce sparsity by zeroing small coefficients\n",
    "        lambda_[I] = 0\n",
    "        \n",
    "        # Step 6: Ridge regression update for large coefficients (J)\n",
    "        if len(J) > 0:\n",
    "            Phi_J = Phi[:, J]  # Submatrix corresponding to non-zero coefficients\n",
    "            A = Phi_J.T @ Phi_J + ridge_reg_param * np.eye(len(J))  # Regularized Gram matrix\n",
    "            b = Phi_J.T @ U9  # Target vector for regression\n",
    "            \n",
    "            # Solve the ridge regression problem\n",
    "            lambda_[J] = np.linalg.solve(A, b)\n",
    "        \n",
    "        # Debugging logs\n",
    "        print(f\"Iteration {iteration + 1}: Non-zero coefficients = {len(J)}\")\n",
    "        \n",
    "        # Convergence check\n",
    "        if np.linalg.norm(lambda_ - prev_lambda, ord=2) < tol:\n",
    "            print(\"Converged!\")\n",
    "            break\n",
    "        \n",
    "        # Optionally decrease the ridge regularization parameter\n",
    "        if dynamic_ridge:\n",
    "            ridge_reg_param *= 0.9  # Reduce by 10% each iteration\n",
    "\n",
    "    return lambda_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collocation Points:\n",
      " [[0.         0.        ]\n",
      " [0.03333333 0.        ]\n",
      " [0.06666667 0.        ]\n",
      " ...\n",
      " [0.93333333 1.        ]\n",
      " [0.96666667 1.        ]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_collocation_points(x_range, t_range, n_points, method=\"uniform\"):\n",
    "    \"\"\"\n",
    "    Generate collocation points in the spatio-temporal domain.\n",
    "    \n",
    "    Args:\n",
    "        x_range (tuple): (x_min, x_max), spatial domain.\n",
    "        t_range (tuple): (t_min, t_max), temporal domain.\n",
    "        n_points (int): Total number of collocation points.\n",
    "        method (str): Sampling method - \"uniform\", \"random\", \"sobol\".\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Array of collocation points [N_c, 2], where each row is (x_i, t_i).\n",
    "    \"\"\"\n",
    "    x_min, x_max = x_range\n",
    "    t_min, t_max = t_range\n",
    "\n",
    "    if method == \"uniform\":\n",
    "        # Create a uniform grid of points\n",
    "        n_x = int(np.sqrt(n_points))  # Number of points in x\n",
    "        n_t = int(np.sqrt(n_points))  # Number of points in t\n",
    "        x = np.linspace(x_min, x_max, n_x)\n",
    "        t = np.linspace(t_min, t_max, n_t)\n",
    "        x, t = np.meshgrid(x, t)\n",
    "        points = np.column_stack([x.ravel(), t.ravel()])\n",
    "\n",
    "    elif method == \"random\":\n",
    "        # Randomly sample points\n",
    "        x = np.random.uniform(x_min, x_max, n_points)\n",
    "        t = np.random.uniform(t_min, t_max, n_points)\n",
    "        points = np.column_stack([x, t])\n",
    "\n",
    "    elif method == \"sobol\":\n",
    "        # Use Sobol sequence for quasi-random sampling\n",
    "        from scipy.stats.qmc import Sobol\n",
    "        sobol = Sobol(d=2)\n",
    "        samples = sobol.random(n_points)\n",
    "        x = x_min + (x_max - x_min) * samples[:, 0]\n",
    "        t = t_min + (t_max - t_min) * samples[:, 1]\n",
    "        points = np.column_stack([x, t])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Choose from 'uniform', 'random', 'sobol'.\")\n",
    "    \n",
    "    return points\n",
    "\n",
    "# Example usage:\n",
    "x_range = (0, 1)  # Spatial domain\n",
    "t_range = (0, 1)  # Temporal domain\n",
    "n_points = 1000   # Total number of collocation points\n",
    "\n",
    "# Generate collocation points using uniform grid\n",
    "collocation_points = generate_collocation_points(x_range, t_range, n_points, method=\"uniform\")\n",
    "print(\"Collocation Points:\\n\", collocation_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ** or pow(): 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m variables \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     50\u001b[0m d_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Allowing higher-degree polynomials up to x^3\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m candidate_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_candidate_functions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(candidate_matrix)\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36mgenerate_candidate_functions\u001b[1;34m(variables, d_max, trigonometric, additional_functions)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, d_max \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m         terms\u001b[38;5;241m.\u001b[39mappend(\u001b[43mvar\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43md\u001b[49m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 3. Mixed polynomial terms\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, d_max \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for ** or pow(): 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "def generate_candidate_functions(variables, d_max, trigonometric=True, additional_functions=['log', 'exp']):\n",
    "    terms = []\n",
    "    \n",
    "    # 1. Constant term\n",
    "    terms.append(1)\n",
    "    \n",
    "    # 2. Polynomial terms\n",
    "    for var in variables:\n",
    "        for d in range(1, d_max + 1):\n",
    "            terms.append(var**d)\n",
    "    \n",
    "    # 3. Mixed polynomial terms\n",
    "    for d in range(2, d_max + 1):\n",
    "        for comb in combinations_with_replacement(variables, d):\n",
    "            term = 1\n",
    "            for v in comb:\n",
    "                term *= v\n",
    "            terms.append(term)\n",
    "    \n",
    "    # 4. Trigonometric terms\n",
    "    if trigonometric:\n",
    "        for var in variables:\n",
    "            terms.append(np.sin(var))\n",
    "            terms.append(np.cos(var))\n",
    "    \n",
    "    # 5. Mixed trigonometric terms\n",
    "    if trigonometric:\n",
    "        for comb in combinations_with_replacement(variables, 2):\n",
    "            terms.append(np.sin(comb[0]) * np.cos(comb[1]))\n",
    "    \n",
    "    # 6. Additional function terms: Logarithmic and Exponential\n",
    "    for var in variables:\n",
    "        if 'log' in additional_functions:\n",
    "            terms.append(np.log(var))\n",
    "        if 'exp' in additional_functions:\n",
    "            terms.append(np.exp(var))\n",
    "    \n",
    "    # 7. Mixed Additional Function Terms\n",
    "    for comb in combinations_with_replacement(variables, 2):\n",
    "        if 'log' in additional_functions and 'exp' in additional_functions:\n",
    "            terms.append(np.log(comb[0]) * np.exp(comb[1]))\n",
    "    \n",
    "    return np.array(terms)\n",
    "\n",
    "# Example Usage:\n",
    "variables = ['x', 't']\n",
    "d_max = 3  # Allowing higher-degree polynomials up to x^3\n",
    "candidate_matrix = generate_candidate_functions(variables, d_max)\n",
    "print(candidate_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_candidate_library(model, x, t, max_degree=2):\n",
    "    \"\"\"\n",
    "    Generate candidate terms automatically using a neural network model in PyTorch.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network that predicts u(x, t).\n",
    "        x: Tensor of spatial points (requires gradient).\n",
    "        t: Tensor of temporal points (requires gradient).\n",
    "        max_degree: Maximum polynomial degree to include.\n",
    "        \n",
    "    Returns:\n",
    "        candidates (dict): Dictionary of candidate terms evaluated at (x, t).\n",
    "        Phi (Tensor): Candidate library matrix (N_collocation_points x N_terms).\n",
    "    \"\"\"\n",
    "    # Ensure inputs require gradients for automatic differentiation\n",
    "    x.requires_grad_(True)\n",
    "    t.requires_grad_(True)\n",
    "\n",
    "    # Compute the prediction and first-order derivatives\n",
    "    u = model(x, t)  # Neural network output\n",
    "    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "\n",
    "    # Compute second-order derivatives\n",
    "    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "\n",
    "    # Construct basic terms\n",
    "    candidates = {\n",
    "        \"1\": torch.ones_like(u),  # Constant term\n",
    "        \"u\": u,                  # Predicted field variable\n",
    "        \"u_x\": u_x,              # First spatial derivative\n",
    "        \"u_t\": u_t,              # First temporal derivative\n",
    "        \"u_xx\": u_xx             # Second spatial derivative\n",
    "    }\n",
    "\n",
    "    # Add polynomial terms (e.g., u^2, u^3, ...)\n",
    "    for i in range(2, max_degree + 1):\n",
    "        candidates[f\"u^{i}\"] = u ** i\n",
    "\n",
    "    # Add mixed terms (e.g., u * u_x, u * u_t)\n",
    "    candidates[\"u * u_x\"] = u * u_x\n",
    "    candidates[\"u * u_t\"] = u * u_t\n",
    "\n",
    "    # Combine terms into a candidate library matrix (Φ)\n",
    "    Phi = torch.cat([term.reshape(-1, 1) for term in candidates.values()], dim=1)\n",
    "\n",
    "    return candidates, Phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class PhysicsInformedNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PhysicsInformedNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 50),   # Input: (x, t)\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 1)    # Output: u(x, t)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        inputs = torch.cat([x, t], dim=1)  # Concatenate x and t along columns\n",
    "        return self.model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_collocation_points(x_range, t_range, n_points):\n",
    "    \"\"\"\n",
    "    Generate collocation points in the spatio-temporal domain.\n",
    "    \n",
    "    Args:\n",
    "        x_range: Tuple specifying the spatial range (x_min, x_max).\n",
    "        t_range: Tuple specifying the temporal range (t_min, t_max).\n",
    "        n_points: Number of collocation points.\n",
    "        \n",
    "    Returns:\n",
    "        x, t: Tensors of spatial and temporal points.\n",
    "    \"\"\"\n",
    "    x = np.random.uniform(x_range[0], x_range[1], n_points)\n",
    "    t = np.random.uniform(t_range[0], t_range[1], n_points)\n",
    "    x = torch.tensor(x, dtype=torch.float32).reshape(-1, 1)\n",
    "    t = torch.tensor(t, dtype=torch.float32).reshape(-1, 1)\n",
    "    return x, t\n",
    "\n",
    "# Example: Generate 1000 collocation points in [0, 1] x [0, 1]\n",
    "x_range, t_range = (0, 1), (0, 1)\n",
    "x, t = generate_collocation_points(x_range, t_range, n_points=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Terms:\n",
      "1: Shape = torch.Size([1000, 1])\n",
      "u: Shape = torch.Size([1000, 1])\n",
      "u_x: Shape = torch.Size([1000, 1])\n",
      "u_t: Shape = torch.Size([1000, 1])\n",
      "u_xx: Shape = torch.Size([1000, 1])\n",
      "u^2: Shape = torch.Size([1000, 1])\n",
      "u * u_x: Shape = torch.Size([1000, 1])\n",
      "u * u_t: Shape = torch.Size([1000, 1])\n",
      "\n",
      "Candidate Library (Φ):\n",
      "torch.Size([1000, 8])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the neural network\n",
    "model = PhysicsInformedNN()\n",
    "\n",
    "# Generate the candidate terms library\n",
    "max_degree = 2  # Include terms up to u^2\n",
    "candidates, Phi = generate_candidate_library(model, x, t, max_degree)\n",
    "\n",
    "# Print the candidate terms\n",
    "print(\"Candidate Terms:\")\n",
    "for term_name, values in candidates.items():\n",
    "    print(f\"{term_name}: Shape = {values.shape}\")\n",
    "\n",
    "print(\"\\nCandidate Library (Φ):\")\n",
    "print(Phi.shape)  # Output: (1000, Number of candidate terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, -0.0684,  0.0452,  ...,  0.0047, -0.0031,  0.0102],\n",
       "        [ 1.0000, -0.1540,  0.0972,  ...,  0.0237, -0.0150,  0.0153],\n",
       "        [ 1.0000, -0.1439,  0.0890,  ...,  0.0207, -0.0128,  0.0158],\n",
       "        ...,\n",
       "        [ 1.0000, -0.0398,  0.0305,  ...,  0.0016, -0.0012,  0.0067],\n",
       "        [ 1.0000, -0.1452,  0.0526,  ...,  0.0211, -0.0076,  0.0235],\n",
       "        [ 1.0000, -0.0679,  0.0433,  ...,  0.0046, -0.0029,  0.0114]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(Phi):\n",
    "    \"\"\"\n",
    "    Normalize each column of the candidate library Φ.\n",
    "    \"\"\"\n",
    "    norms = torch.norm(Phi, dim=0, keepdim=True)  # Compute column norms\n",
    "    Phi_normalized = Phi / norms\n",
    "    return Phi_normalized\n",
    "\n",
    "# Normalize Φ\n",
    "Phi_normalized = normalize_columns(Phi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0316, -0.0177,  0.0224,  ...,  0.0081, -0.0113,  0.0195],\n",
       "        [ 0.0316, -0.0398,  0.0481,  ...,  0.0413, -0.0545,  0.0292],\n",
       "        [ 0.0316, -0.0372,  0.0440,  ...,  0.0361, -0.0466,  0.0300],\n",
       "        ...,\n",
       "        [ 0.0316, -0.0103,  0.0151,  ...,  0.0028, -0.0044,  0.0127],\n",
       "        [ 0.0316, -0.0375,  0.0260,  ...,  0.0367, -0.0278,  0.0448],\n",
       "        [ 0.0316, -0.0176,  0.0214,  ...,  0.0080, -0.0107,  0.0216]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Phi_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boot_DA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
